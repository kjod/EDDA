---
title: "Assignment 6, EDDA 2017"
author: "Martin de la Riva(11403799) and Kieran O'Driscoll(11426438), Group 23"
date: "18 May 2017"
output:
  word_document: default
  pdf_document: default
  html_document: default
highlight: tango
fontsize: 11pt
---

# Assignment 6

## Exercise 1
```{r}
fruitflies=read.table('fruitflies.txt', header=TRUE)
fruitflies$loglongevity <- log(fruitflies$longevity)
```

### 2.
```{r}
plot(loglongevity~thorax, pch=as.character(activity), col=as.numeric(activity), data=fruitflies)
abline(lm(loglongevity~thorax, data=fruitflies), col="blue")
```

In the plot above, longevity seems to increase with torax.

```{r}
# per activity:
boxplot(fruitflies$loglongevity~fruitflies$activity)
```

In these boxplots, it can be seen how high activity has a significantly low longevity than low and isolated activity. Those two last activities remain in similar longevity values.

```{r}
# thorax per activity (is there a significant difference between them?)
boxplot(fruitflies$thorax~fruitflies$activity)
```

Lastly, we plot activity with respect to thorax, to see if thorax lengths are equally distributed along the activity groups. This is important, as if one group was full of bigger thorax fruitflies, this could affect the result of the experiment. The activity groups are seen to actually have similar thorax values.

### 3.

```{r}
flieslm = lm(loglongevity~activity, data=fruitflies)
anova(flieslm)
```

Sexual activity seems to significantly influence longevity, with a p-value of 1.798e-07.

### 4.

```{r}
confint(flieslm)
```
The more sexual activity the less longetivity.
In the Confidence Intervals for the different activities, this can be seen:
Confidence Intervals for $\mu_{high}$ activity:   [3.4796296, 3.7246190]
Confidence Intervals for $\mu_{isolated}$ - $\mu_{high}$: [0.3439909, 0.6904582]
Confidence Intervals for $\mu_{low}$ - $\mu_{high}$:      [0.2244780, 0.5709453]
Therefore, high has the lowest longevity, and isolated the highest (isolated > low > high).

### 5.

```{r}
flieslm2 = lm(loglongevity~thorax+activity, data=fruitflies)
anova(flieslm2)
```
```{r}
drop1(flieslm2,test="F")
```

After testing it (both with anova and drop1, we get very similar results on both) we can conclude that both factors (thorax and activity) have a significant influence on the longevity.

### 6.

```{r}
summary(flieslm2)
```

As said before, the more sexual activity, the lowest longevity. Therefore, sexual activity influences negatively longevity (Isolated > Low > High).
final model: 1.21893 + 2.97899*thorax + 0.40998 (isolated)
                                      + 0.28570 (low)
                                      - 0.69568 (high)

For a fly with an average thorax:
```{r}
mean(fruitflies$thorax)
###    loglongevity_isolated= 1.21893 + 2.97899*0.8245333 + 0.40998 = 4.085186
1.21893 + 2.97899*mean(fruitflies$thorax) + 0.40998
###    loglongevity_low     = 1.21893 + 2.97899*0.8245333 + 0.28570 = 3.960906
1.21893 + 2.97899*mean(fruitflies$thorax) + 0.28570
###    loglongevity_high    = 1.21893 + 2.97899*0.8245333 - 0.69568 = 2.979526
1.21893 + 2.97899*mean(fruitflies$thorax) - 0.69568
```
```{r}
min(fruitflies$thorax)
###    loglongevity_isolated= 1.21893 + 2.97899*0.64 + 0.40998 = 3.535464
1.21893 + 2.97899*min(fruitflies$thorax) + 0.40998
###    loglongevity_low     = 1.21893 + 2.97899*0.64 + 0.28570 = 3.411184
1.21893 + 2.97899*min(fruitflies$thorax) + 0.28570
###    loglongevity_high    = 1.21893 + 2.97899*0.64 - 0.69568 = 2.429804
1.21893 + 2.97899*min(fruitflies$thorax) - 0.69568
```

### 7.

```{r}
plot(loglongevity~thorax, pch=unclass(activity), col=as.numeric(activity), data=fruitflies)
for (i in 1:3) abline(lm(loglongevity~thorax, data=fruitflies[as.numeric(fruitflies$activity)==i,]), col=i)
legend("bottomright", legend=levels(fruitflies$activity), col=c(1,2,3), lty=1, cex=0.5)
```

Lines have similar slope, which denotes that thorax influences similarly between activities.

### 8.

We prefer the analysis with thorax, as it is more complete. Also, it is possible to detect if there could be a difference in longevity between groups because of flies with significantly different thorax, instead of sexual activity. The analysis are fine, both factors do influence longevity.

### 9.

```{r}
par(mfrow=c(1,2))
qqnorm(residuals(flieslm2))
plot(fitted(flieslm2),residuals(flieslm2))
```

Normality is clearly met by the residuals, although heteroscedasticity is not that clear.

```{r}
par(mfrow=c(1,2))
flieslm3 = lm(longevity~thorax+activity, data=fruitflies)
qqnorm(residuals(flieslm3))
plot(fitted(flieslm3),residuals(flieslm3))
```

In this case heteroscedasticity seems more clear, which may mean that taking the logarithm of longevity was not a good decition.

## Exercise 2

```{r}
psi=read.table('psi.txt', header=TRUE)
```

### 2.

```{r}
psi$psi=factor(psi$psi)
psi$passed=factor(psi$passed)
psilm = glm(passed~psi+gpa, data=psi, family=binomial)
```

### 3.

```{r}
drop1(psilm,test="Chisq")
summary(psilm)
```

According to the tests above, psi has a significant influence in whether the student passes or not, and the estimation on when psi is 1 is a positive number. Therefore, it that influence is positive, which would mean that psi does improve the learning of students.

### 4.

```{r}
# Student with psi with a gpa is 3
1/(1+exp(-(-11.602 + 2.338*1 + 3.063*3)))
# Student without psi with a gpa is 3
1/(1+exp(-(-11.602 + 2.338*0 + 3.063*3)))
```

### 5.

```{r}
exp(2.338)
```

The odds of passing the assignment rendered by students instructed with psi is 10.36049. This means that having studied using the psi method increases the chance of passing the assingment by 10.36049%. This value is independent from gpa.

### 6.

```{r}
x=matrix(c(3,15,8,6),2,2)
fisher.test(x)
```

15 is the number of students who did not receive psi and didn't showed improvement.
6 is the number of students who received psi and didn't show impovement.
The hypothesis tested by Fisher's exact test is if there is independence between the 2 factors (having psi and improving). This is rejected (p-value < 0.05) which proves that there is a dependence between them, and concluding that psi is more helpful to improve than the previous teaching method.

### 7.

It does not take into account the amount of improvement found per student, but besides that it is a correct experiment.

### 8.

1st:
advantage: It takes more information into account, and can estimate probability of passing having the data of the student.
disadvantage: It is a more complex method and may be sensitive to outliers.

2nd:
advantage: It is a simple method to find significance on improvement.
disadvantage: It does not take into account the amount of improvement found per student

## Exercise 3

### 1.
 
```{r}
africa_data=read.table("africa.txt", header=TRUE)
par(mfrow=c(2,2))
hist(rpois(100, lambda = 1))
hist(rpois(100, lambda = 5))
hist(rpois(100, lambda = 10))
hist(rpois(100, lambda = 15))

```

```{r}
par(mfrow=c(2,2))
hist(rpois(1000, lambda = 1))
hist(rpois(1000, lambda = 5))
hist(rpois(1000, lambda = 10))
hist(rpois(1000, lambda = 15))
```

### 2.

```{r}
par(mfrow=c(2,2))
qqnorm(rpois(500, lambda = 1))
qqnorm(rpois(500, lambda = 15))
qqnorm(rpois(100, lambda = 15))
qqnorm(rpois(1000, lambda = 15))
```

What can be seen from question one is that as lambda and n increases, the poisson distribution better approximates a normal distribution. This is seen in the histograms in question 1 and is further backed up by the QQ plots. As the poisson distribution gets closer to approximating the normal distribution, the poisson distributions would be in the same location-scale family as they would have properties similar to a normal distribution.

```{r}
africa_data=read.table("africa.txt", header=TRUE)
par(mfrow=c(3,2))
hist(rpois(1000, lambda = 2))
hist(rpois(1000, lambda = 25))
hist(rpois(1000, lambda = 50))
hist(rpois(1000, lambda = 75))
hist(rpois(1000, lambda = 100))
hist(rpois(1000, lambda = 240))
```


### 3

```{r}
#Analysisof variance
galaglm_full=glm(miltcoup~oligarchy+pollib+parties+pctvote+popn+size+numelec +numregim,family=poisson,data=africa_data)
error1 = summary(galaglm_full)$r.squared
summary(galaglm_full)
```

### 4.
Removing numelec has it had the highest p-value.
```{r}

#Analysisof variance
galaglm=glm(miltcoup~oligarchy+pollib+parties+pctvote+popn+size +numregim,family=poisson,data=africa_data)
summary(galaglm)
```
Removing numregim.

```{r}
galaglm=glm(miltcoup~oligarchy+pollib+parties+pctvote+popn+size,family=poisson,data=africa_data)
summary(galaglm)
```
Removing size.

```{r}
galaglm=glm(miltcoup~oligarchy+pollib+parties+pctvote+popn,family=poisson,data=africa_data)
summary(galaglm)
```
Removing popn.

```{r}
galaglm=glm(miltcoup~oligarchy+pollib+parties+pctvote,family=poisson,data=africa_data)
summary(galaglm)
```
And finally removing pctvote.

```{r}
galaglm=glm(miltcoup~oligarchy+pollib+parties,family=poisson,data=africa_data)
summary(galaglm)
```


###5.

```{r}
par(mfrow=c(2,2))
attach(africa_data)
plot(fitted(galaglm),residuals(galaglm))
plot(residuals(galaglm),parties)
plot(residuals(galaglm),pollib)
plot(residuals(galaglm),oligarchy)
```

```{r}
par(mfrow=c(1,3))
plot(residuals(galaglm_full),parties)
plot(log(fitted(galaglm)),residuals(galaglm))
plot(log(fitted(galaglm)),residuals(galaglm,type="response"))
```


The response residuals clearly increase with the (logarithm) of the fitted values,
as expected under a Poisson model.

Next, the model from Q3 will be investigated to see if it follows the same pattern.

```{r}
par(mfrow=c(1,3))
plot(residuals(galaglm_full),parties)
plot(log(fitted(galaglm_full)),residuals(galaglm_full))
plot(log(fitted(galaglm_full)),residuals(galaglm_full,type="response"))
```

While the response residuals clearly increase with the logarithm of the fitted values, the step down approach looks to contain less clear patterns in it's data. In the full model with all explanatory variables, there looks to be much clearer linear structures within the data compared to the step down model. This could be due to the removed variables. During the process of the step down approach in Q4 what can be seen is that some of the variables become less significant as variables are removed. For example, in the last step the variable pctvote is removed. This reduces the p-value of the variable parties. By removing pctvote, the relationship between pctvote and parties is removed which could affect the model if the is a dependency between these two variables.

```{r}
pairs(pctvote~parties)
```

However, from the pairs graph there does not seem to be a strong correlation.
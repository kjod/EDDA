---
title: "Assignment 4 & 5, EDDA 2017"
author: "Martin de la Riva(11403799) and Kieran O'Driscoll(11426438), Group 23"
date: "08 May 2017"
output:
  word_document: default
  pdf_document: default
  html_document: default
highlight: tango
fontsize: 11pt
---
```{r}
library(multcomp)
library(lme4)
```

# Assignment 6

## Exercise 3

### 1.
For this exercise  
```{r}
africa_data=read.table("africa.txt", header=TRUE)
par(mfrow=c(2,2))
hist(rpois(100, lambda = 1))
hist(rpois(100, lambda = 5))
hist(rpois(100, lambda = 10))
hist(rpois(100, lambda = 15))

```

```{r}
par(mfrow=c(2,2))
hist(rpois(1000, lambda = 1))
hist(rpois(1000, lambda = 5))
hist(rpois(1000, lambda = 10))
hist(rpois(1000, lambda = 15))
```

### 2.

```{r}
par(mfrow=c(2,2))
qqnorm(rpois(500, lambda = 1))
qqnorm(rpois(500, lambda = 15))
qqnorm(rpois(100, lambda = 15))
qqnorm(rpois(1000, lambda = 15))
```

What can be seen from question one is that as lambda and n increases, the poisson distribution further approximates a normal distribution. This is seen in the histgrams in question 1 and is further backed up by the QQ plots. As the poisson distribution gets closer to approximating the normal distribution, the Poisson distributions would be in the same location-scale family as they would have properties similar to a normal distribution.


#transform distrubution, see if it looks same afterwards
```{r}
africa_data=read.table("africa.txt", header=TRUE)
par(mfrow=c(3,2))
hist(rpois(1000, lambda = 2))
hist(rpois(1000, lambda = 25))
hist(rpois(1000, lambda = 50))
hist(rpois(1000, lambda = 75))
hist(rpois(1000, lambda = 100))
hist(rpois(1000, lambda = 240))
```


### 3

```{r}
#Analysisof variance
galaglm_full=glm(miltcoup~oligarchy+pollib+parties+pctvote+popn+size+numelec +numregim,family=poisson,data=africa_data)
error1 = summary(galaglm_full)$r.squared
summary(galaglm_full)
```

### 4.
Removing numelec has it had the gighest p-value.
```{r}

#Analysisof variance
galaglm=glm(miltcoup~oligarchy+pollib+parties+pctvote+popn+size +numregim,family=poisson,data=africa_data)
summary(galaglm)
```
Removing numregim.

```{r}
galaglm=glm(miltcoup~oligarchy+pollib+parties+pctvote+popn+size,family=poisson,data=africa_data)
summary(galaglm)
```
Removing size.

```{r}
galaglm=glm(miltcoup~oligarchy+pollib+parties+pctvote+popn,family=poisson,data=africa_data)
summary(galaglm)
```
Removing popn.

```{r}
galaglm=glm(miltcoup~oligarchy+pollib+parties+pctvote,family=poisson,data=africa_data)
summary(galaglm)
```
And finally removing pctvote.

```{r}
galaglm=glm(miltcoup~oligarchy+pollib+parties,family=poisson,data=africa_data)
summary(galaglm)
```


###5.

```{r}
print(error1)
print(error2)
```

Full model(Q3)
Step down model(Q4)

```{r}
par(mfrow=c(2,2))
attach(africa_data)
plot(fitted(galaglm),residuals(galaglm))
plot(residuals(galaglm),parties)
plot(residuals(galaglm),pollib)
plot(residuals(galaglm),oligarchy)
```

```{r}
par(mfrow=c(1,3))
plot(residuals(galaglm_full),parties)
plot(log(fitted(galaglm)),residuals(galaglm))
plot(log(fitted(galaglm)),residuals(galaglm,type="response"))
#plot(1:36,cooks.distance(galaglm))
print(residuals(galaglm))
```
```{r}
  
```

The response residuals clearly increase with the (logarithm) of the fitted values,
as expected under a Poisson model.
#compare r^2 scores
